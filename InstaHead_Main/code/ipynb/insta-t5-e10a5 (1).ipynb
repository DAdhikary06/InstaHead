{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["eLBFs9x0W8g1","9DNFK_uPXRbv","ZHImFw46XjMq","QtaZ7VDDcDzT"]},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11966359,"sourceType":"datasetVersion","datasetId":7524611}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installing Pip","metadata":{"_uuid":"b648c009-2f3d-4943-afbf-c098f987c926","_cell_guid":"2b343686-8212-4826-90cd-b4d90f1923c8","trusted":true,"collapsed":false,"id":"G0dPHESGKk3g","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Install required packages\n!pip install transformers datasets rouge_score nltk pandas numpy matplotlib seaborn tqdm torch scikit-learn\n!pip install rouge_score\n# !pip install --upgrade --force-reinstall transformers","metadata":{"_uuid":"ed11d419-55d8-49a5-baee-c76824dcb681","_cell_guid":"21de4fec-397f-4c41-a624-834e837fb8fc","trusted":true,"collapsed":false,"id":"fQ6VHk10KjbA","outputId":"43b8cd1e-df78-4882-96c5-7f0636a0bfe8","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:17:54.769109Z","iopub.execute_input":"2025-05-27T09:17:54.769344Z","iopub.status.idle":"2025-05-27T09:19:13.156326Z","shell.execute_reply.started":"2025-05-27T09:17:54.769322Z","shell.execute_reply":"2025-05-27T09:19:13.155489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading the libraries","metadata":{"_uuid":"5eb451b6-d2ff-490d-a489-f2a537e1e14b","_cell_guid":"978550c6-747f-4c59-ae4d-3425a0788ca1","trusted":true,"collapsed":false,"id":"yfwHs1_0D_L_","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    T5ForConditionalGeneration,\n    T5Tokenizer,\n    get_linear_schedule_with_warmup,\n)\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom rouge_score import rouge_scorer\n# import time\nfrom tqdm.notebook import tqdm\nimport os","metadata":{"_uuid":"71cef664-ab17-4c35-aa0f-359a2606ef1a","_cell_guid":"a304d350-2085-464e-b391-7563cb7a1ced","trusted":true,"collapsed":false,"id":"6rne2luiDTgy","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:19:48.567145Z","iopub.execute_input":"2025-05-27T09:19:48.567733Z","iopub.status.idle":"2025-05-27T09:20:12.428619Z","shell.execute_reply.started":"2025-05-27T09:19:48.567696Z","shell.execute_reply":"2025-05-27T09:20:12.428078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download NLTK resources\nnltk.download('punkt')","metadata":{"_uuid":"9e97d984-c1a8-4ab9-8852-f17db7393080","_cell_guid":"d1b8dfe6-0b67-4410-b610-7514a7fa598b","trusted":true,"collapsed":false,"id":"g82VJedULAFd","outputId":"818537d4-02fc-4bd0-964b-ee0b6bf27eb2","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:21:24.374647Z","iopub.execute_input":"2025-05-27T09:21:24.375475Z","iopub.status.idle":"2025-05-27T09:21:24.515753Z","shell.execute_reply.started":"2025-05-27T09:21:24.375450Z","shell.execute_reply":"2025-05-27T09:21:24.514963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Set the random Seeds","metadata":{"_uuid":"5bbbab02-92cc-42cf-8b7a-a669f3ccc136","_cell_guid":"994e161e-1dd1-4843-b26a-3e3ac0d9bb6d","trusted":true,"collapsed":false,"id":"dE-5l8Y_0IPy","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"''' Note: Set the random seeds means that the every time you run the code, You will get same results '''\n# Set random seeds for reproducibility\nseed = 4\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"_uuid":"130d8969-7208-4fc2-86f4-33ebebcac9bf","_cell_guid":"eb798fa9-f28e-4e24-997f-096d53584ced","trusted":true,"collapsed":false,"id":"rInvHPxLSBt6","outputId":"50675e2e-bc9a-4580-8b91-35fcf606175e","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:21:28.246445Z","iopub.execute_input":"2025-05-27T09:21:28.246731Z","iopub.status.idle":"2025-05-27T09:21:28.256493Z","shell.execute_reply.started":"2025-05-27T09:21:28.246708Z","shell.execute_reply":"2025-05-27T09:21:28.255917Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define class and their parameter","metadata":{"_uuid":"a2900b16-f782-4511-99a0-7a3a479fffcc","_cell_guid":"884563a5-c43b-4c77-acf4-a34e9cdb780d","trusted":true,"collapsed":false,"id":"3DMYiiUy0SIL","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define paths and parameters\nmodel_name = \"t5-base\"  # Can also use 't5-small' for faster training or 't5-large' for better results\nmax_input_length = 512  # T5 can handle up to 512 tokens\nmax_output_length = 64  # Headlines are usually short\nbatch_size = 8 # Adjust based on your GPU memory\nepochs = 10\nlearning_rate = 5.6e-5\nweight_decay_rate = 0.01\nwarmup_steps = 500","metadata":{"_uuid":"1385677e-a925-4804-812d-cfaa6fdfc0b5","_cell_guid":"b99c9786-624c-4e33-9f5b-0be37a7ddf0a","trusted":true,"collapsed":false,"id":"QfkG0Yu5SFDq","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:21:39.792582Z","iopub.execute_input":"2025-05-27T09:21:39.792854Z","iopub.status.idle":"2025-05-27T09:21:39.797141Z","shell.execute_reply.started":"2025-05-27T09:21:39.792835Z","shell.execute_reply":"2025-05-27T09:21:39.796413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define the dataset class for our news data\nclass NewsDataset(Dataset):\n    def __init__(self, articles, headlines, categories, tokenizer, max_input_length, max_output_length):\n        self.articles = articles\n        self.headlines = headlines\n        self.categories = categories\n        self.tokenizer = tokenizer\n        self.max_input_length = max_input_length\n        self.max_output_length = max_output_length\n\n    def __len__(self):\n        return len(self.articles)\n\n    def __getitem__(self, idx):\n        article = self.articles[idx]\n        headline = self.headlines[idx]\n        category = self.categories[idx]\n\n        # Prepend task prefix and category for T5\n        input_text = f\"summarize: {category}: {article}\"\n\n        # Tokenize inputs and outputs\n        input_encoding = self.tokenizer(\n            input_text,\n            max_length=self.max_input_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n )\n\n        output_encoding = self.tokenizer(\n            headline,\n            max_length=self.max_output_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n\n        # Convert the target tokens to format expected by T5\n        target_ids = output_encoding[\"input_ids\"]\n        target_ids[target_ids == 0] = -100  # Ignore padding tokens in loss calculation\n\n        return {\n            \"input_ids\": input_encoding[\"input_ids\"].flatten(),\n            \"attention_mask\": input_encoding[\"attention_mask\"].flatten(),\n            \"target_ids\": target_ids.flatten()\n\n        }","metadata":{"_uuid":"e31c329e-4dae-4ecf-b969-cbe3efb7d901","_cell_guid":"de8109df-2997-4b15-9902-c6bb07b41688","trusted":true,"collapsed":false,"id":"pXT8_xP7WS7S","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:21:43.933740Z","iopub.execute_input":"2025-05-27T09:21:43.933998Z","iopub.status.idle":"2025-05-27T09:21:43.940384Z","shell.execute_reply.started":"2025-05-27T09:21:43.933979Z","shell.execute_reply":"2025-05-27T09:21:43.939727Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Prepare Data","metadata":{"_uuid":"9721c345-f587-4c6c-9c77-7180433eef18","_cell_guid":"7c7e036c-9a03-4e27-b369-f9e1cd622e6a","trusted":true,"collapsed":false,"id":"vc725IGGlkIy","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def load_and_prepare_data(file_paths, seed=42):\n    \"\"\"Load and prepare the news dataset from multiple CSV files.\"\"\"\n    # Load data from all file paths\n    dataframes = [pd.read_csv(path) for path in file_paths]\n\n    # Concatenate all dataframes into a single dataframe\n    data = pd.concat(dataframes, ignore_index=True)\n\n    # Shuffle the data\n    df = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n\n    # Dataset Shape\n    print(f\"DataSet Shape : {df.shape} \")\n    print(f\"\\nColumn Names : {df.columns.to_list()} \")\n\n    # Make sure the column name match your dataset\n    # If column names are different , rename it\n\n    column_map ={\n        # Map your actual column names to required column names\n        # 'your_article_column':'news_article'\n        # 'your_headline_column':'news_headline'\n        # 'your_category_column':'news_category'\n\n    }\n\n    if column_map:\n     df = df.rename(columns=column_map)\n\n    # Ensure the required columns exist\n    required_columns = ['news_article', 'news_headline', 'news_category']\n    for col in required_columns:\n        if col not in df.columns:\n            raise ValueError(f\"Required column '{col}' not found in dataset. Please rename your columns.\")\n\n    # No of News Categories\n    print(f\"\\nNumber of News Categories: \\n{df['news_category'].value_counts()}\")\n\n    # Checking NaN values and Handle these values\n    nan_articles = df['news_article'].isna().sum()\n    nan_headlines = df['news_headline'].isna().sum()\n\n    if nan_articles > 0 or nan_headlines > 0:\n      print(f\"\\nFound {nan_articles} NaN articles and {nan_headlines} NaN headlines\")\n      print(\"\\nRemoving rows with NaN values...\")\n      df = df.dropna(subset=['news_article', 'news_headline']) # remove missing or NaN values of listed columns\n\n    # Split into train, validation, and test sets\n    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=seed, stratify=df['news_category'])\n    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=seed, stratify=temp_df['news_category'])\n\n    print(f\"\\nTrain size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}, DataFrame size: {len(df)}\")\n\n    return train_df, val_df, test_df, df\n\n\n# Define the all paths to the CSV files\npaths = [\n    '/kaggle/input/inshort-dataset/inshort_news_data-1.csv',\n    '/kaggle/input/inshort-dataset/inshort_news_data-2.csv',\n    '/kaggle/input/inshort-dataset/inshort_news_data-3.csv',\n    '/kaggle/input/inshort-dataset/inshort_news_data-4.csv',\n    '/kaggle/input/inshort-dataset/inshort_news_data-5.csv',\n    '/kaggle/input/inshort-dataset/inshort_news_data-6.csv'\n]\n\n# Load and prepare the data\ntrain_df, val_df, test_df, df = load_and_prepare_data(paths)","metadata":{"_uuid":"e98d6ce6-0034-4648-a06d-1c8e12d6957a","_cell_guid":"926cd58b-dd1e-4551-9135-6d3b9ad67f78","trusted":true,"collapsed":false,"id":"ZIzfzq4xkLvN","outputId":"2b0a7689-7a4f-40fa-fdb1-98dc6775c72b","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:21:53.407631Z","iopub.execute_input":"2025-05-27T09:21:53.408138Z","iopub.status.idle":"2025-05-27T09:21:53.487546Z","shell.execute_reply.started":"2025-05-27T09:21:53.408110Z","shell.execute_reply":"2025-05-27T09:21:53.486975Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create a Train, Test or Validation Dataset","metadata":{"_uuid":"9f4b7127-1817-4fbb-a330-960005a00a7d","_cell_guid":"0a3252fe-9347-4a15-b062-4da009697055","trusted":true,"collapsed":false,"id":"mZXcd8p81O9W","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Initialize tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n# ''' After Save the trained model '''\n# save_directory = \"/content/drive/MyDrive/T5_Headline_Model\"\n# tokenizer = T5Tokenizer.from_pretrained(save_directory)\n\ntrain_dataset = NewsDataset(\n    train_df['news_article'].tolist(),\n    train_df['news_headline'].tolist(),\n    train_df['news_category'].tolist(),  # Include categories\n    tokenizer,\n    max_input_length,\n    max_output_length\n)\n\nval_dataset = NewsDataset(\n    val_df['news_article'].tolist(),\n    val_df['news_headline'].tolist(),\n    val_df['news_category'].tolist(),  # Include categories\n    tokenizer,\n    max_input_length,\n    max_output_length\n)\n\ntest_dataset = NewsDataset(\n    test_df['news_article'].tolist(),\n    test_df['news_headline'].tolist(),\n    test_df['news_category'].tolist(),  # Include categories\n    tokenizer,\n    max_input_length,\n    max_output_length\n)","metadata":{"_uuid":"e66447e1-217a-4284-9150-93a9aed58130","_cell_guid":"cd274272-ed61-4a0f-9495-47291bd2a374","trusted":true,"collapsed":false,"id":"S3dsnjI0lyKK","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:21:58.606838Z","iopub.execute_input":"2025-05-27T09:21:58.607423Z","iopub.status.idle":"2025-05-27T09:21:59.767410Z","shell.execute_reply.started":"2025-05-27T09:21:58.607401Z","shell.execute_reply":"2025-05-27T09:21:59.766809Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create the DataLoader","metadata":{"_uuid":"d191889d-79e8-4575-9438-31d6b130ac2e","_cell_guid":"7faea6e6-6eca-428d-b00a-77685836307d","trusted":true,"collapsed":false,"id":"xRAVseT24YBs","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Import DataLoader\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\n\n# Create DataLoaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Load T5 model or already pretrained model\nmodel = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n# model = T5ForConditionalGeneration.from_pretrained(save_directory).to(device)\n\n# Define optimizer and scheduler\noptimizer = AdamW(model.parameters(), lr=learning_rate)  # Use AdamW instead of AdamWeightDecay\nnum_training_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps)","metadata":{"_uuid":"793b24d6-d8a0-4f6b-988e-64d8147aabc8","_cell_guid":"32dd4036-1e68-43b8-bd1b-1695c1428393","trusted":true,"collapsed":false,"id":"JhyYKXmQuASh","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:22:08.046842Z","iopub.execute_input":"2025-05-27T09:22:08.047550Z","iopub.status.idle":"2025-05-27T09:22:11.983434Z","shell.execute_reply.started":"2025-05-27T09:22:08.047517Z","shell.execute_reply":"2025-05-27T09:22:11.982874Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the model","metadata":{"_uuid":"cabaf656-91e7-4639-8f92-3842d22ea895","_cell_guid":"7c6ea3da-06b2-40fd-b977-f987dbcd6b3e","trusted":true,"collapsed":false,"id":"r515UFnhPoYz","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Train the model for a single epochs\ndef train(model, dataloader, optimizer, scheduler, device):\n    model.train() # Puts the model in training mode\n    total_loss = 0\n    # Iterate through the each batches\n    for batch in tqdm(dataloader, desc=\"Training\"):\n        # Move input data to the save device as the model\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        target_ids = batch[\"target_ids\"].to(device)\n\n        optimizer.zero_grad() # Clear previous gradients\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=target_ids\n        )\n\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"_uuid":"c3ee1bf0-3dcb-4b81-b314-0c51980e1221","_cell_guid":"2a38cec4-a31f-4053-bf92-f44e27132cf8","trusted":true,"collapsed":false,"id":"GnadSlNxuG2q","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:22:17.847237Z","iopub.execute_input":"2025-05-27T09:22:17.847812Z","iopub.status.idle":"2025-05-27T09:22:17.852860Z","shell.execute_reply.started":"2025-05-27T09:22:17.847789Z","shell.execute_reply":"2025-05-27T09:22:17.851962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluated Loss Value\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            target_ids = batch[\"target_ids\"].to(device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=target_ids\n            )\n\n            loss = outputs.loss\n            total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"_uuid":"7cc54862-8bb4-416e-b529-5749b55f30b9","_cell_guid":"f2276d87-ee36-4777-a027-0ac8954d4c9e","trusted":true,"collapsed":false,"id":"buyeNKrPuMbL","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:22:28.662709Z","iopub.execute_input":"2025-05-27T09:22:28.663397Z","iopub.status.idle":"2025-05-27T09:22:28.667659Z","shell.execute_reply.started":"2025-05-27T09:22:28.663375Z","shell.execute_reply":"2025-05-27T09:22:28.667108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\nbest_val_loss = float('inf')\ntrain_losses = []\nval_losses = []\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    train_loss = train(model, train_dataloader, optimizer, scheduler, device)\n    val_loss = evaluate(model, val_dataloader, device)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n\n    # Save the model if validation loss improves\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        model_save_path = f\"best_t5_headline_model_epoch_{epoch+1}.pt\"\n        torch.save(model.state_dict(), model_save_path)\n        print(f\"Saved best model to {model_save_path}\")\n\nprint(\"\\nTraining finished.\")","metadata":{"_uuid":"b2befcca-9a36-4596-9d62-bc07b9a6d7e7","_cell_guid":"a545a449-95a9-4849-a588-9423cd0021ca","trusted":true,"collapsed":false,"id":"rmHYvTYluUnd","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T09:23:33.321659Z","iopub.execute_input":"2025-05-27T09:23:33.322320Z","iopub.status.idle":"2025-05-27T10:34:17.272355Z","shell.execute_reply.started":"2025-05-27T09:23:33.322296Z","shell.execute_reply":"2025-05-27T10:34:17.271438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a DataFrame from the loss lists\nloss_df = pd.DataFrame({\n    'Epoch': list(range(1, epochs + 1)),\n    'Train Loss': train_losses,\n    'Validation Loss': val_losses\n})\n\n# Display the table\nprint(\"\\nLoss Summary:\")\nprint(loss_df.to_string(index=False))","metadata":{"_uuid":"020584b0-a15f-4c83-94e8-d2ba00d63e8c","_cell_guid":"17310c5d-b2e2-4069-8f20-d6ffee1461d4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T10:38:05.999826Z","iopub.execute_input":"2025-05-27T10:38:06.000549Z","iopub.status.idle":"2025-05-27T10:38:06.007375Z","shell.execute_reply.started":"2025-05-27T10:38:06.000524Z","shell.execute_reply":"2025-05-27T10:38:06.006697Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_df.to_csv(\"training_loss_summary.csv\", index=False)","metadata":{"_uuid":"caba1415-aed3-47e8-859c-f565b8090e1d","_cell_guid":"ffd4ba5c-ed93-4506-a7d5-1bc8c0a6abff","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T10:36:36.199062Z","iopub.execute_input":"2025-05-27T10:36:36.199378Z","iopub.status.idle":"2025-05-27T10:36:36.209225Z","shell.execute_reply.started":"2025-05-27T10:36:36.199357Z","shell.execute_reply":"2025-05-27T10:36:36.208366Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training and validation loss\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, epochs + 1), train_losses, label='Train Loss')\nplt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n\nplt.title('Training vs Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.xticks(range(1, epochs + 1))\nplt.legend()\nplt.tight_layout()\n\n# Save the plot to a file\nplt.savefig('loss_plot.png')\n\n# Show the plot\nplt.show()","metadata":{"_uuid":"217437ae-d641-4155-8f24-d7e2e734d486","_cell_guid":"e74ff2b6-5beb-4999-bd49-54740f491322","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T10:54:06.056953Z","iopub.execute_input":"2025-05-27T10:54:06.057680Z","iopub.status.idle":"2025-05-27T10:54:06.422226Z","shell.execute_reply.started":"2025-05-27T10:54:06.057656Z","shell.execute_reply":"2025-05-27T10:54:06.421411Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the best model after Training","metadata":{"_uuid":"e1eea2ce-c762-40a3-af7e-35cf3e878c30","_cell_guid":"9094b3e0-1706-4a0d-bbee-4758b7a5c472","trusted":true,"collapsed":false,"id":"My0OmKZcUUpd","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Load the best model for evaluation\nbest_model_path = f\"best_t5_headline_model_epoch_{epoch+1}.pt\" # Assuming the last saved model is the best\n# If you want the actual best one, you'd need to track the path of `best_val_loss`'s model\n# best_model_path = \"path_to_the_best_model_you_saved\"\ntry:\n  model.load_state_dict(torch.load(best_model_path, map_location=device))\n  print(f\"Loaded model from {best_model_path}\")\nexcept FileNotFoundError:\n  print(f\"Warning: Best model not found at {best_model_path}. Using the model from the last epoch.\")","metadata":{"_uuid":"f4cd3f20-f384-4932-99c2-a97ae3c1907d","_cell_guid":"6c48d196-e6c9-4a84-84dc-9cfa919fe05a","trusted":true,"collapsed":false,"id":"S5hWyXbkUQNE","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T10:54:31.714472Z","iopub.execute_input":"2025-05-27T10:54:31.715008Z","iopub.status.idle":"2025-05-27T10:54:32.306421Z","shell.execute_reply.started":"2025-05-27T10:54:31.714986Z","shell.execute_reply":"2025-05-27T10:54:32.305764Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generating Headline","metadata":{"_uuid":"9d71185f-4084-4254-98c9-e16f740af7c5","_cell_guid":"c2c7c7bf-671c-4733-9cc4-5b102b105e49","trusted":true,"collapsed":false,"id":"arqGFrPcUoB2","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def generate_headline(model, tokenizer, article, category, device, max_length=64):\n    \"\"\"Generate a headline for a given article and category.\"\"\"\n    model.eval()\n    input_text = f\"summarize: {category}: {article}\"\n    input_encoding = tokenizer(\n        input_text,\n        max_length=max_input_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\"\n    ).to(device)\n\n    with torch.no_grad():\n        generated_ids = model.generate(\n            input_ids=input_encoding[\"input_ids\"],\n            attention_mask=input_encoding[\"attention_mask\"],\n            max_length=max_output_length,\n            num_beams=5,\n            length_penalty=0.6,\n            early_stopping=True\n        )\n\n    headline = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return headline","metadata":{"_uuid":"27274680-bc02-49cf-916e-6d3c255ca12e","_cell_guid":"052cf5df-b916-447c-9946-41685250a0ed","trusted":true,"collapsed":false,"id":"UOHwLDwUuagV","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T10:54:36.613347Z","iopub.execute_input":"2025-05-27T10:54:36.613645Z","iopub.status.idle":"2025-05-27T10:54:36.619259Z","shell.execute_reply.started":"2025-05-27T10:54:36.613623Z","shell.execute_reply":"2025-05-27T10:54:36.618616Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generating Headline Calculate Rouge Score for Test Set","metadata":{"_uuid":"ecf98dc6-0aa3-4b7d-9531-538841bb5a79","_cell_guid":"0b7d53d9-18d6-4411-a75d-cff1105261b7","trusted":true,"collapsed":false,"id":"Qda9QIHmUv1-","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Evaluate on the test set and calculate ROUGE scores\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nreference_headlines = test_df['news_headline'].tolist()\ngenerated_headlines = []\n\nfor i in tqdm(range(len(test_dataset)), desc=\"Generating Headlines for Test Set\"):\n    sample = test_dataset[i]\n    input_ids = sample[\"input_ids\"].unsqueeze(0).to(device)\n    attention_mask = sample[\"attention_mask\"].unsqueeze(0).to(device)\n\n    # Need to reconstruct the article and category to pass to generate_headline\n    article = test_df.iloc[i]['news_article']\n    category = test_df.iloc[i]['news_category']\n\n    generated_headline = generate_headline(model, tokenizer, article, category, device, max_output_length)\n    generated_headlines.append(generated_headline)\n\n# Calculate ROUGE scores\nrouge_scores = [scorer.score(ref, gen) for ref, gen in zip(reference_headlines, generated_headlines)]\navg_rouge1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\navg_rouge2 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\navg_rougel = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\nprint(f\"\\nAverage ROUGE-1 F-measure: {avg_rouge1:.4f}\")\nprint(f\"Average ROUGE-2 F-measure: {avg_rouge2:.4f}\")\nprint(f\"Average ROUGE-L F-measure: {avg_rougel:.4f}\")","metadata":{"_uuid":"0bd73bb7-cb7f-4d8c-b840-64f11ba1962f","_cell_guid":"ec8592d3-a452-4e5b-b5b2-6af437df2629","trusted":true,"collapsed":false,"id":"AoYvhG--nk2_","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T10:38:48.309221Z","iopub.execute_input":"2025-05-27T10:38:48.309865Z","iopub.status.idle":"2025-05-27T10:46:12.552820Z","shell.execute_reply.started":"2025-05-27T10:38:48.309835Z","shell.execute_reply":"2025-05-27T10:46:12.552237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prompt: How to save genereted output in txt format in other folder save rough score\n\n# Create a directory to save the output if it doesn't exist\noutput_dir = \"/kaggle/working\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Define the path for the output file\noutput_file_path = os.path.join(output_dir, \"rouge_scores.txt\")\n\n# Save the generated output and ROUGE scores to a text file\nwith open(output_file_path, \"w\") as f:\n    f.write(\"--- Generated Headlines and ROUGE Scores ---\\n\\n\")\n    f.write(\"\\n--- Average ROUGE Scores ---\\n\")\n    f.write(f\"Average ROUGE-1 F-measure: {avg_rouge1:.4f}\\n\")\n    f.write(f\"Average ROUGE-2 F-measure: {avg_rouge2:.4f}\\n\")\n    f.write(f\"Average ROUGE-L F-measure: {avg_rougel:.4f}\\n\")\n\nprint(f\"Generated output and ROUGE scores saved to {output_file_path}\")","metadata":{"_uuid":"05b6a2e9-87f6-4f48-b669-8716a8d5b94f","_cell_guid":"40b72485-d29f-4837-8ed3-4b80973b46ac","trusted":true,"collapsed":false,"id":"d_GobjIYeUlI","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T10:57:11.217919Z","iopub.execute_input":"2025-05-27T10:57:11.218658Z","iopub.status.idle":"2025-05-27T10:57:11.224464Z","shell.execute_reply.started":"2025-05-27T10:57:11.218634Z","shell.execute_reply":"2025-05-27T10:57:11.223788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Display Some Generated and Actual Headline based on test data","metadata":{"_uuid":"af087c57-7aa9-4e96-9a2a-d861f4fd7251","_cell_guid":"7a4baa92-380a-4fcb-8c87-b8980b8b5f47","trusted":true,"collapsed":false,"id":"ZsUJS7yCWuo7","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Example: Display some generated headlines vs. actual headlines\n\nprint(\"\\n--- Sample Generated vs. Actual Headlines ---\")\nfor i in range(min(10, len(test_df))): # Display up to 10 examples\n    print(f\"\\nArticle: {test_df.iloc[i]['news_article'][:200]}...\") # Display truncated article\n    print(f\"Category: {test_df.iloc[i]['news_category']}\")\n    print(f\"Actual Headline: {test_df.iloc[i]['news_headline']}\")\n    print(f\"Generated Headline: {generated_headlines[i]}\")","metadata":{"_uuid":"3e19aa1d-32b0-495a-b162-e07f28dee6b6","_cell_guid":"00346fb1-317d-41a4-b69b-f7981c8e5cf4","trusted":true,"collapsed":false,"id":"dem-2OelW4As","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T10:57:24.855360Z","iopub.execute_input":"2025-05-27T10:57:24.855833Z","iopub.status.idle":"2025-05-27T10:57:24.862599Z","shell.execute_reply.started":"2025-05-27T10:57:24.855810Z","shell.execute_reply":"2025-05-27T10:57:24.861795Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test the model using Custom aricle input without generating WorldCloud (Optional)","metadata":{"_uuid":"bfccefe5-22c4-41f2-b262-f723abb5b95b","_cell_guid":"43f628ed-7e9e-40be-80bd-6f86315f2aa0","trusted":true,"collapsed":false,"id":"eLBFs9x0W8g1","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def test_with_custom_input(model, tokenizer, device):\n    \"\"\"Test the model with custom input articles and category, including Word Cloud.\"\"\"\n    print(\"\\n=== Custom Article Test ===\")\n    print(\"Enter or paste an article to generate a headline. Type 'exit' to quit.\")\n\n    # Optional: Define stopwords if you want to remove common words\n    # stop_words = set(stopwords.words('english')) # Use the language of your articles\n\n    while True:\n        article = input(\"\\nArticle: \")\n        if article.lower() == 'exit':\n            break\n\n        category = input(\"Category (e.g. technology, sports, automobile): \").strip()\n        if not category:\n            print(\"Category cannot be empty. Please enter a category.\")\n            continue\n\n        # --- Generate Headline ---\n        # Preprocess input with category\n        input_text = f\"summarize: {category}: {article}\"\n        input_encoding = tokenizer(\n            input_text,\n            max_length=max_input_length, # Make sure max_input_length is defined\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n        ).to(device)\n\n        # Generate headline\n        model.eval()\n        with torch.no_grad():\n            generated_ids = model.generate(\n                input_ids=input_encoding[\"input_ids\"],\n                attention_mask=input_encoding[\"attention_mask\"],\n                max_length=max_output_length, # Make sure max_output_length is defined\n                num_beams=5,\n                length_penalty=0.6,\n                early_stopping=True\n            )\n\n        # Decode generated headline\n        headline = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n        print(f\"\\nGenerated Headline: {headline}\")\n\ntest_with_custom_input(model, tokenizer, device)","metadata":{"_uuid":"8c05f504-42ba-4b5a-9deb-d4443455fbf2","_cell_guid":"a28eaff6-393f-4f97-be5b-7e95efbd8603","trusted":true,"collapsed":false,"id":"-7O-_nTHmVHN","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate Headline and WorldCloud based on article","metadata":{"_uuid":"d7924306-ae6e-4011-829c-ada8430582b2","_cell_guid":"7e6cb236-f909-4c7a-bae4-d2471c733daa","trusted":true,"collapsed":false,"id":"lfOBjiFMXJNG","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from wordcloud import WordCloud\n\ndef test_single_article(model, tokenizer, device, max_input_length=512, max_output_length=32):\n\n    # --- Get input from user ---\n    print(\"\\n=== Single Article Test ===\")\n    article = input(\"Enter article text:\\n\")\n    if not article.strip():\n        print(\"Article cannot be empty.\")\n        return\n\n    category = input(\"Enter category (e.g., technology, sports, automobile): \").strip()\n    if not category:\n        print(\"Category cannot be empty.\")\n        return\n\n    # --- Inner function to generate and display word cloud ---\n    def generate_and_plot_wordcloud(text, title=\"Word Cloud\"):\n        print(f\"\\nGenerating {title}...\")\n        try:\n            wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n            plt.figure(figsize=(10, 5))\n            plt.imshow(wordcloud, interpolation='bilinear')\n            plt.axis(\"off\")\n            plt.title(title)\n            plt.show()\n        except Exception as e:\n            print(f\"Could not generate Word Cloud: {e}\")\n\n    # --- Prepare input for model ---\n    input_text = f\"summarize: {category}: {article}\"\n    input_encoding = tokenizer(\n        input_text,\n        max_length=max_input_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\"\n    ).to(device)\n\n    # --- Generate Headline ---\n    model.eval()\n    with torch.no_grad():\n        generated_ids = model.generate(\n            input_ids=input_encoding[\"input_ids\"],\n            attention_mask=input_encoding[\"attention_mask\"],\n            max_length=max_output_length,\n            num_beams=5,\n            length_penalty=0.6,\n            early_stopping=True\n        )\n\n    headline = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    # --- Generate Word Cloud ---\n    generate_and_plot_wordcloud(article, title=\"Word Cloud of the Article\")\n\n    # Return the generated headline\n    return print(f\"\\nGenerated Headline: {headline}\")\n\n# Run custom input test\ntest_single_article(model, tokenizer, device)","metadata":{"_uuid":"81c52e86-c61b-4a17-a88b-bc06d43a9a40","_cell_guid":"91e9ca69-8f77-419a-9829-466ff6c4ac8d","trusted":true,"collapsed":false,"id":"DMBD8CcMuskK","outputId":"177ffd31-396f-4266-e379-91159fefbc33","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save the Trained Model in directory","metadata":{"_uuid":"38d871c5-1fd9-416d-9c4f-879483790714","_cell_guid":"338eac44-1873-428b-a3ae-fc1df94b95d6","trusted":true,"collapsed":false,"id":"9DNFK_uPXRbv","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define the directory in the writable Kaggle path\nsave_directory = \"/kaggle/working/T5_Headline_Model\"\n\n# Create the directory if it doesn't exist\nif not os.path.exists(save_directory):\n    os.makedirs(save_directory)\n    print(f\"Created directory: {save_directory}\")\n\n# Save the fine-tuned model and tokenizer\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved to {save_directory}\")\n\n# To load the model later\n# loaded_model = T5ForConditionalGeneration.from_pretrained(save_directory)\n# loaded_tokenizer = T5Tokenizer.from_pretrained(save_directory)","metadata":{"_uuid":"c642f465-97ba-444d-9c5f-889f6bb34b28","_cell_guid":"6251b3b8-7d02-4e4a-82ad-7f5a273a58a3","trusted":true,"collapsed":false,"id":"OZ81jiAioYT9","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T11:01:23.148059Z","iopub.execute_input":"2025-05-27T11:01:23.148348Z","iopub.status.idle":"2025-05-27T11:01:24.996423Z","shell.execute_reply.started":"2025-05-27T11:01:23.148327Z","shell.execute_reply":"2025-05-27T11:01:24.995663Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plots the Distribution","metadata":{"_uuid":"0bbc7f8e-a1b9-414d-8b92-79afccf9bdc0","_cell_guid":"ddb3a5d7-7415-4724-8f04-53da453c3c39","trusted":true,"collapsed":false,"id":"ZHImFw46XjMq","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Plots the distribution of token lengths for news articles and headlines.\ndef plot_length_distributions(df):\n\n    if 'news_article' not in df.columns or 'news_headline' not in df.columns:\n        print(\"Error: DataFrame must contain 'news_article' and 'news_headline' columns.\")\n        return\n\n    # Calculate token lengths (using whitespace tokenization as a proxy)\n    # For more accurate tokenization length, you would use the T5Tokenizer\n    # Here, we use simple word count as a quicker approximation for visualization\n    df['article_length'] = df['news_article'].apply(lambda x: len(str(x).split()))\n    df['headline_length'] = df['news_headline'].apply(lambda x: len(str(x).split()))\n\n    plt.figure(figsize=(12, 6))\n\n    # Plot article length distribution\n    plt.subplot(1, 2, 1)\n    sns.histplot(df['article_length'], bins=50, kde=True)\n    plt.title('Distribution of Article Lengths (Words)')\n    plt.xlabel('Number of Words')\n    plt.ylabel('Frequency')\n    plt.xlim(0, df['article_length'].quantile(0.99)) # Limit x-axis for better visualization\n\n    # Plot headline length distribution\n    plt.subplot(1, 2, 2)\n    sns.histplot(df['headline_length'], bins=30, kde=True, color='orange')\n    plt.title('Distribution of Headline Lengths (Words)')\n    plt.xlabel('Number of Words')\n    plt.ylabel('Frequency')\n    plt.xlim(0, df['headline_length'].quantile(0.99)) # Limit x-axis for better visualization\n    plt.tight_layout()\n    plt.show()\n\n    return df\n\n''' Re-assign value '''\ndf=plot_length_distributions(df)\n\n''' Plot the distribution for train/val/test sets separately '''\n# plot_length_distributions(train_df)\n# plot_length_distributions(val_df)\n# plot_length_distributions(test_df)\n\n'''Plot the distribution for train/val/test sets together '''\nplot_length_distributions(pd.concat([train_df, val_df, test_df]))","metadata":{"_uuid":"27e10dd0-9fe1-4542-8f59-02a93927a81c","_cell_guid":"10db2c66-3b93-47f4-a169-511951a80e77","trusted":true,"collapsed":false,"id":"t-UbMziG0F9T","outputId":"2c620d1d-b2a1-4c5d-940a-48274dfcee45","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T11:02:09.490299Z","iopub.execute_input":"2025-05-27T11:02:09.491046Z","iopub.status.idle":"2025-05-27T11:02:11.238167Z","shell.execute_reply.started":"2025-05-27T11:02:09.491025Z","shell.execute_reply":"2025-05-27T11:02:11.237337Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize relationships between Article complexity and Headline quality","metadata":{"_uuid":"02c63ec1-f602-45b2-9081-162427840784","_cell_guid":"4c94e15a-95a7-4d7e-9c49-ec716e99c356","trusted":true,"collapsed":false,"id":"QtaZ7VDDcDzT","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"nltk.download('punkt_tab')\n\n# Function to calculate article complexity\ndef calculate_article_complexity(text):\n    \"\"\"Calculates article complexity based on the number of sentences.\"\"\"\n    if pd.isna(text) or not isinstance(text, str): # It checks the 'text' is 'NaN' or other than string\n        return 0\n    sentences = sent_tokenize(text)\n    return len(sentences)\n\n# Function to calculate headline quality\ndef calculate_headline_quality(headline):\n    \"\"\"Calculates headline quality based on headline length (word count).\"\"\"\n    if pd.isna(headline) or not isinstance(headline, str): # It checks the 'text' is 'NaN' or other than string\n        return 0\n    return len(headline.split())\n\n# Apply the complexity and quality calculations to the dataframe\ndf['article_complexity'] = df['news_article'].apply(calculate_article_complexity)\ndf['headline_quality'] = df['news_headline'].apply(calculate_headline_quality)\n\n# Visualize the relationship using a scatter plot\nplt.figure(figsize=(14,8))\nsns.scatterplot(x='article_complexity', y='headline_quality', data=df, alpha=0.6, s=10)\nplt.title('Relationship between Article Complexity and Headline Quality')\nplt.xlabel('Article Complexity (Number of Sentences)')\nplt.ylabel('Headline Quality (Headline Length in Words)')\nplt.grid(True)\nplt.show()\n\n# You can also explore the relationship by category\nplt.figure(figsize=(14, 8))\nsns.scatterplot(x='article_complexity', y='headline_quality', hue='news_category', data=df.sample(n=2000, random_state=42), alpha=0.6, s=15) # Sample for clarity\nplt.title('Relationship between Article Complexity and Headline Quality by Category (Sampled Data)')\nplt.xlabel('Article Complexity (Number of Sentences)')\nplt.ylabel('Headline Quality (Headline Length in Words)')\nplt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(True)\nplt.show()","metadata":{"_uuid":"815a0472-611b-4c21-b4b1-71f8b3561d42","_cell_guid":"26401dc6-8a15-474f-a23b-33cda79183d0","trusted":true,"collapsed":false,"id":"x91OdzSj1YyM","outputId":"d70679b6-a011-4c44-c384-3e612808f07f","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T11:02:14.668699Z","iopub.execute_input":"2025-05-27T11:02:14.669376Z","iopub.status.idle":"2025-05-27T11:02:15.777097Z","shell.execute_reply.started":"2025-05-27T11:02:14.669352Z","shell.execute_reply":"2025-05-27T11:02:15.776399Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Correlation Matrix","metadata":{"_uuid":"67cdf05e-c08d-4b50-853d-434f0ab21387","_cell_guid":"335f1048-a22e-4510-a27a-cb0b90adb246","trusted":true,"collapsed":false,"id":"w9UeRzathtd2","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Correlation matrix between numerical features\nnumerical_df = df[['article_complexity', 'headline_quality', 'article_length', 'headline_length']] # This are numerical columns\n\n# Drop potential NaN values that might interfere with correlation calculation\nnumerical_df = numerical_df.dropna()\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Matrix')\nplt.show()","metadata":{"_uuid":"2aebe8b5-19e3-4eb1-940e-da1c4d7533a2","_cell_guid":"fb47ab3f-b853-4980-8dad-523efef709bc","trusted":true,"collapsed":false,"id":"RunNDafFhi8F","outputId":"272de9d6-d176-496b-f9e8-137aed180280","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-27T11:02:21.388164Z","iopub.execute_input":"2025-05-27T11:02:21.388489Z","iopub.status.idle":"2025-05-27T11:02:21.588091Z","shell.execute_reply.started":"2025-05-27T11:02:21.388471Z","shell.execute_reply":"2025-05-27T11:02:21.587298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"4d311f4f-80cd-4616-a96e-97fca58146a8","_cell_guid":"b2836e5a-cc2b-4ab9-bed9-b6ff49551d9c","trusted":true,"collapsed":false,"id":"iGIOajpha2-m","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}